{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85b5b2d",
   "metadata": {},
   "source": [
    "In this notebook I benchmark the implementation of the CWRNN vs. the implementation of a standard RNN.\n",
    "The CWRNN should avoid some computations, but the sparse multiplication logic could  actually slow down the execution, compared to a simple matvec for computinh $h_{t+1}$ in the standard RNN. \n",
    "I'll execute two experiments\n",
    "- unbatched small inputs\n",
    "- batched big inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5719f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path.append(\"..\")\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import numpy as np\n",
    "import equinox as eqx  # pytree utilities\n",
    "from rnn_jax.cells import ElmanRNNCell, ClockWorkRNNCell\n",
    "from rnn_jax.layers import RNNEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f433fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn:\n",
      "85.1 μs ± 2.03 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "cw-rnn:\n",
      "244 μs ± 10.2 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "rnn = RNNEncoder(ElmanRNNCell(1, 64, key=jr.key(0)))\n",
    "cwrnn = RNNEncoder(\n",
    "    ClockWorkRNNCell(\n",
    "        1, [16, 16, 16, 16], [2, 4, 8, 16], nonlinearity=jax.nn.relu, key=jr.key(0)\n",
    "    )\n",
    ")\n",
    "x = jr.uniform(jr.key(1), (256, 1))\n",
    "jit_rnn = eqx.filter_jit(rnn)\n",
    "jit_rnn(x)\n",
    "jit_cwrnn = eqx.filter_jit(cwrnn)\n",
    "jit_cwrnn(x)\n",
    "print(\"rnn:\")\n",
    "%timeit jit_rnn(x)\n",
    "print(\"cw-rnn:\")\n",
    "%timeit jit_cwrnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109b281",
   "metadata": {},
   "source": [
    "CW-RNN is considerably slower ($\\approx$ 3x) in the unbatched case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15fb53b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn:\n",
      "98.7 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "cw-rnn:\n",
      "97.7 ms ± 1.45 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = jr.uniform(jr.key(1), (256, 100, 10))\n",
    "rnn = RNNEncoder(ElmanRNNCell(10, 1024, key=jr.key(0)))\n",
    "cwrnn = RNNEncoder(\n",
    "    ClockWorkRNNCell(\n",
    "        10, [256 // 4] * 4, [4, 16, 64, 256], nonlinearity=jax.nn.relu, key=jr.key(0)\n",
    "    )\n",
    ")\n",
    "vmap_rnn = eqx.filter_vmap(rnn)\n",
    "vmap_rnn(x)\n",
    "vmap_cwrnn = eqx.filter_vmap(cwrnn)\n",
    "vmap_cwrnn(x)\n",
    "print(\"rnn:\")\n",
    "%timeit vmap_cwrnn(x)\n",
    "print(\"cw-rnn:\")\n",
    "%timeit vmap_cwrnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b3093",
   "metadata": {},
   "source": [
    "When batching, cwrnn catches up in speed. Probably optimizing more the logic should make it go faster than a standard RNN. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
